{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvPHZgafqLAKNeP0zZxuZb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maryasad/AI-Prompt-Engineering/blob/main/WebScraping_Knee_X_Ray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlYxmVF0e6dU",
        "outputId": "9fe75d1b-76f5-4f63-f374-83da1c98d087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "                                               Title  \\\n",
            "0  Improving Radiographic Fracture Recognition Pe...   \n",
            "1  Artificial intelligence for detection of effus...   \n",
            "2  Comparison of diagnostic accuracy of point-of-...   \n",
            "3  The Feature Ambiguity Mitigate Operator model ...   \n",
            "4             [Knee cartilage injuries in athletes].   \n",
            "5  Osteoporosis diagnosis in knee X-rays by trans...   \n",
            "6                       A Young Skier with Leg Pain.   \n",
            "7  Incidence and characteristics of ligamentous k...   \n",
            "8  The anteromedial retinaculum in ACL-injured kn...   \n",
            "9  Artificial intelligence versus radiologist in ...   \n",
            "\n",
            "                                             Authors  \\\n",
            "0  Guermazi A, Tannoury C, Kompel AJ, Murakami AM...   \n",
            "1  Cohen I, Sorin V, Lekach R, Raskin D, Segev M,...   \n",
            "2  Kozaci N, Avci M, Yuksel S, Donertas E, Karaca...   \n",
            "3  Wu HZ, Yan LF, Liu XQ, Yu YZ, Geng ZJ, Wu WJ, ...   \n",
            "4                                           Horng A.   \n",
            "5                                  Wani IM, Arora S.   \n",
            "6             Roque S, Fones L, Maloney K, Zhang XC.   \n",
            "7  Dawood MH, Shahzad MG, Perveen H, Daniyal M, S...   \n",
            "8  Grunenberg O, Gerwing M, Oeckenp√∂hler S, Peez ...   \n",
            "9  Liu Y, Liu W, Chen H, Xie S, Wang C, Liang T, ...   \n",
            "\n",
            "                                         Link  \n",
            "0  https://pubmed.ncbi.nlm.nih.gov//34931859/  \n",
            "1  https://pubmed.ncbi.nlm.nih.gov//38608501/  \n",
            "2  https://pubmed.ncbi.nlm.nih.gov//35107590/  \n",
            "3  https://pubmed.ncbi.nlm.nih.gov//33452403/  \n",
            "4  https://pubmed.ncbi.nlm.nih.gov//36877296/  \n",
            "5  https://pubmed.ncbi.nlm.nih.gov//36185321/  \n",
            "6  https://pubmed.ncbi.nlm.nih.gov//37055298/  \n",
            "7  https://pubmed.ncbi.nlm.nih.gov//38264408/  \n",
            "8  https://pubmed.ncbi.nlm.nih.gov//38469949/  \n",
            "9  https://pubmed.ncbi.nlm.nih.gov//37869340/  \n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 pandas\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# PubMed search URL\n",
        "BASE_URL = \"https://pubmed.ncbi.nlm.nih.gov/\"\n",
        "\n",
        "def fetch_articles(query, start_year, end_year, max_results=10):\n",
        "    articles = []\n",
        "    page = 1\n",
        "\n",
        "    while len(articles) < max_results:\n",
        "        # Construct query URL\n",
        "        url = f\"{BASE_URL}?term={query}&filter=years.{start_year}-{end_year}&page={page}\"\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Find article entries\n",
        "        article_blocks = soup.find_all('article', class_='full-docsum')\n",
        "\n",
        "        # Break loop if no more articles\n",
        "        if not article_blocks:\n",
        "            break\n",
        "\n",
        "        for block in article_blocks:\n",
        "            try:\n",
        "                # Extract article title\n",
        "                title = block.find('a', class_='docsum-title').text.strip()\n",
        "\n",
        "                # Extract link to article\n",
        "                link = BASE_URL + block.find('a', class_='docsum-title')['href']\n",
        "\n",
        "                # Extract author details (optional)\n",
        "                authors = block.find('span', class_='docsum-authors full-authors').text.strip()\n",
        "\n",
        "                # Append article details\n",
        "                articles.append({'Title': title, 'Authors': authors, 'Link': link})\n",
        "            except Exception as e:\n",
        "                print(f\"Error parsing article: {e}\")\n",
        "\n",
        "            # Stop if max results reached\n",
        "            if len(articles) >= max_results:\n",
        "                break\n",
        "\n",
        "        page += 1  # Move to next page\n",
        "\n",
        "    return articles\n",
        "\n",
        "# Query articles about knee-fracture detection in X-rays (2010-2024)\n",
        "query = \"knee fracture detection X-ray\"\n",
        "start_year = 2021\n",
        "end_year = 2025\n",
        "max_results = 10  # Set desired limit of articles\n",
        "\n",
        "articles = fetch_articles(query, start_year, end_year, max_results)\n",
        "\n",
        "# Save results to a DataFrame\n",
        "df = pd.DataFrame(articles)\n",
        "\n",
        "# Save as CSV for offline use\n",
        "df.to_csv(\"knee_fracture_articles.csv\", index=False)\n",
        "\n",
        "# Display DataFrame\n",
        "print(df)\n",
        "\n"
      ]
    }
  ]
}